{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ***Deep Deterministic Policy Gradients with Instinctive Network***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-10 16:15:40.646813: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib qt\n",
    "\n",
    "import gym\n",
    "import tensorflow as tf, matplotlib.pyplot as plt, numpy as np\n",
    "\n",
    "from tensorflow.keras.layers import Dense, BatchNormalization \n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from typing import Tuple\n",
    "\n",
    "global_seed = 42\n",
    "tf.random.set_seed(global_seed)\n",
    "np.random.seed(global_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### **OU Action Noise**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OUActionNoise:\n",
    "    def __init__(self, mean, sigma=0.7, theta=0.3, dt=0.1, x0=None):\n",
    "        self.mean = tf.constant(mean, dtype=tf.float32)\n",
    "        self.sigma = tf.constant(sigma, dtype=tf.float32)\n",
    "        self.theta = tf.constant(theta, dtype=tf.float32)\n",
    "        self.dt = tf.constant(dt, dtype=tf.float32)\n",
    "        self.x0 = x0\n",
    "        self.reset()\n",
    "\n",
    "\n",
    "    @tf.function\n",
    "    def __call__(self):\n",
    "        x = self.x_prev + self.theta * (self.mean - self.x_prev) * self.dt + \\\n",
    "            self.sigma * tf.sqrt(self.dt) * tf.random.normal(self.mean.shape)\n",
    "        self.x_prev = x\n",
    "        return x\n",
    "\n",
    "\n",
    "    def reset(self):\n",
    "        if self.x0 is not None:\n",
    "            self.x_prev = tf.constant(self.x0, dtype=tf.float32)\n",
    "        else:\n",
    "            self.x_prev = tf.zeros_like(self.mean)\n",
    "        return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### **Replay Buffer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReplayBuffer(object):\n",
    "    def __init__(self, size, minibatch_size = None):\n",
    "        self.buffer = []\n",
    "        self.minibatch_size = minibatch_size\n",
    "        self.rand_generator = np.random.RandomState()\n",
    "        self.max_size = size\n",
    "\n",
    "\n",
    "    def append(self, state, action, reward, next_state, context, next_context, done):\n",
    "        if self.size() == self.max_size:\n",
    "            del self.buffer[0]\n",
    "        self.buffer.append([state, action, reward, next_state, context, next_context, int(done)])\n",
    "        return\n",
    "\n",
    "\n",
    "    def sample(self):\n",
    "        idxs = self.rand_generator.choice(np.arange(len(self.buffer)), size=self.minibatch_size)\n",
    "        return [self.buffer[idx] for idx in idxs]\n",
    "\n",
    "\n",
    "    def size(self):\n",
    "        return len(self.buffer)\n",
    "\n",
    "\n",
    "    def isMin(self):\n",
    "        return (self.size() >= self.minibatch_size)\n",
    "\n",
    "\n",
    "    def empties(self):\n",
    "        self.buffer.clear()\n",
    "        return\n",
    "\n",
    "\n",
    "    def getEpisode(self):\n",
    "        return self.buffer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### **SOM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SOM:\n",
    "    def __init__(self, m, n, dim, n_iterations, alpha, sigma=None):\n",
    "        self.m = m\n",
    "        self.n = n\n",
    "        self.dim = dim\n",
    "        self.n_iterations = n_iterations\n",
    "        \n",
    "        if sigma is None:\n",
    "            sigma = max(m, n) / 2.0\n",
    "        \n",
    "        self.alpha = tf.Variable(alpha, dtype=tf.float32)\n",
    "        self.sigma = tf.Variable(sigma, dtype=tf.float32)\n",
    "        \n",
    "        self.weights = tf.Variable(tf.random.uniform([m * n, dim]))\n",
    "        self.locations = tf.constant([(i, j) for i in range(m) for j in range(n)], dtype=tf.float32)\n",
    "    \n",
    "    \n",
    "    @tf.function\n",
    "    def get_bmu(self, input_vector):\n",
    "        distances = tf.reduce_sum(tf.square(tf.cast(self.weights, dtype=tf.float32) - tf.cast(input_vector, dtype=tf.float32)), axis=1)\n",
    "        bmu_index = tf.argmin(distances)\n",
    "        return bmu_index\n",
    "    \n",
    "\n",
    "    @tf.function\n",
    "    def update_weights(self, input_vector, bmu_index):\n",
    "        bmu_location = tf.gather(self.locations, bmu_index)\n",
    "        distance_sq = tf.reduce_sum(tf.square(self.locations - bmu_location), axis=1)\n",
    "        neighborhood = tf.exp(-distance_sq / (2 * tf.square(self.sigma)))\n",
    "        \n",
    "        learning = tf.expand_dims(tf.cast(neighborhood, dtype=tf.float32) * tf.cast(self.alpha, dtype=tf.float32), axis=1) * (tf.cast(input_vector, dtype=tf.float32) - tf.cast(self.weights, dtype=tf.float32))\n",
    "        self.weights.assign_add(learning)\n",
    "        return\n",
    "    \n",
    "\n",
    "    @tf.function\n",
    "    def train_step(self, input_vector):\n",
    "        bmu_index = self.get_bmu(input_vector)\n",
    "        self.update_weights(input_vector, bmu_index)\n",
    "        return\n",
    "    \n",
    "\n",
    "    @tf.function\n",
    "    def train(self, input_data):\n",
    "        for _ in range(self.n_iterations):\n",
    "            for vector in input_data:\n",
    "                self.train_step(vector)\n",
    "        return\n",
    "\n",
    "\n",
    "    def index_to_2d(self, index):\n",
    "        i = index // self.n\n",
    "        j = index % self.n\n",
    "        return (i, j)\n",
    "\n",
    "\n",
    "    @tf.function\n",
    "    def activate(self, input_vector):\n",
    "        distances = tf.reduce_sum(tf.square(tf.cast(self.weights, dtype=tf.float32) - tf.cast(input_vector, dtype=tf.float32)), axis=1)\n",
    "        return tf.reshape(distances, [self.m, self.n])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### **Instinctive Weights**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InstinctiveWeights:\n",
    "    def __init__(self, som_shape: Tuple[int, int]):\n",
    "        self.som_shape = som_shape\n",
    "        self.num_neurons = tf.reduce_prod(self.som_shape)\n",
    "        self.weights = tf.Variable(tf.zeros((self.num_neurons, self.num_neurons)), dtype=tf.float32)\n",
    "        self.decay = 0.999\n",
    "\n",
    "\n",
    "    @tf.function\n",
    "    def _neuron_to_position(self, neuron):\n",
    "        i, j = neuron\n",
    "        return tf.cast(i * self.som_shape[1] + j, tf.int32)\n",
    "\n",
    "\n",
    "    @tf.function\n",
    "    def reinforce_connection(self, n1, n2):\n",
    "        pos1 = self._neuron_to_position(n1)\n",
    "        pos2 = self._neuron_to_position(n2)\n",
    "        value = self.weights[pos1, pos2]\n",
    "        value += 0.1\n",
    "        value = tf.clip_by_value(value, 0, 1)\n",
    "        self.weights[pos1, pos2].assign(value)\n",
    "        self.weights[pos2, pos1].assign(value)\n",
    "\n",
    "\n",
    "    @tf.function\n",
    "    def step(self):\n",
    "        self.weights.assign(self.weights * self.decay)\n",
    "\n",
    "\n",
    "    @tf.function\n",
    "    def get_weight_matrix(self):\n",
    "        return self.weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### **Instinctive Layer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InstinctiveLayer:\n",
    "    def __init__(\n",
    "        self, som_shape, func_x_max, func_x_drop, func_y_max, func_y_min, act_threshold,\n",
    "    ):\n",
    "        self.som_shape = som_shape\n",
    "        self.act_threshold = act_threshold\n",
    "        self.func_x_max = func_x_max\n",
    "        self.func_x_drop = func_x_drop\n",
    "        self.func_y_max = func_y_max\n",
    "        self.func_y_min = func_y_min\n",
    "\n",
    "        self.charges = tf.Variable(tf.zeros(self.som_shape) + self.func_x_max/100, dtype=tf.float32)\n",
    "\n",
    "\n",
    "    @tf.function\n",
    "    def get_act_array(self):\n",
    "        return tf.reshape(self.get_activations(), [-1])\n",
    "\n",
    "\n",
    "    @tf.function\n",
    "    def get_active(self):\n",
    "        act = self.get_activations()\n",
    "        active = tf.where(tf.equal(act, 1))\n",
    "        return [(i, j) for i, j in zip(active[:, 0], active[:, 1])]\n",
    "\n",
    "\n",
    "    @tf.function\n",
    "    def step(self, weights, som_act) -> None:        \n",
    "        charge_delta = tf.reshape(tf.matmul(tf.reshape(self.charges * self.get_activations(), (1, -1)), weights), self.charges.shape)\n",
    "        charge_delta = tf.clip_by_value(charge_delta, 0, self.func_x_max/50)\n",
    "        \n",
    "        som_act *= self.func_x_max/50\n",
    "\n",
    "        self.charges.assign_add(tf.cast(charge_delta, dtype=tf.float32) + tf.cast(som_act, dtype=tf.float32))\n",
    "\n",
    "        mask_above_drop = tf.greater(self.charges, self.func_x_drop)\n",
    "        mask_below_drop = tf.less_equal(self.charges, self.func_x_drop)\n",
    "\n",
    "        self.charges.assign(tf.where(mask_above_drop, self.charges + self.func_x_max/100, self.charges))\n",
    "        self.charges.assign(tf.where(mask_below_drop, self.charges - self.func_x_max/100, self.charges))\n",
    "\n",
    "        self.charges.assign(tf.clip_by_value(self.charges, 0, self.func_x_max))\n",
    "        return\n",
    "\n",
    "\n",
    "    @tf.function\n",
    "    def _apply_activation_function(self, charges):\n",
    "        def func(x):\n",
    "            cond1 = tf.less_equal(x, self.func_x_drop)\n",
    "            cond2 = tf.logical_and(tf.greater(x, self.func_x_drop), tf.less_equal(x, self.func_x_max))\n",
    "            \n",
    "            y1 = tf.cast(self.func_y_max / tf.square(self.func_x_drop), dtype=tf.float32) * tf.cast(tf.square(x), dtype=tf.float32)\n",
    "            y2 = tf.cast(self.func_y_min, dtype=tf.float32) + tf.cast((0 - self.func_y_min) / (self.func_x_max - self.func_x_drop), dtype=tf.float32) * tf.cast(x - self.func_x_drop, dtype=tf.float32)\n",
    "            \n",
    "            return tf.where(cond1, y1, tf.where(cond2, y2, tf.zeros_like(x, dtype=tf.float32)))\n",
    "        \n",
    "        return func(charges)\n",
    "    \n",
    "\n",
    "    @tf.function\n",
    "    def reset_charges(self):\n",
    "        self.charges.assign(tf.zeros(self.som_shape) + self.func_x_max/100)\n",
    "        return\n",
    "    \n",
    "    \n",
    "    @tf.function\n",
    "    def get_activations(self):\n",
    "        activations = self._apply_activation_function(self.charges)\n",
    "        activations = tf.clip_by_value(activations, 0, self.act_threshold)\n",
    "        activations = activations / self.act_threshold\n",
    "        activations = tf.where(tf.greater(self.charges, self.func_x_drop), tf.ones_like(activations) * self.func_x_max/100, activations)\n",
    "        return activations\n",
    "    \n",
    "    \n",
    "    def plot_act_func(self):\n",
    "        # Generate x values\n",
    "        x = np.linspace(0, self.func_x_max, 1000)\n",
    "        y = self._apply_activation_function(x)\n",
    "\n",
    "        # Plot the function\n",
    "        plt.plot(x, y, label=\"Piecewise Function with Repetition\")\n",
    "        plt.xlabel('x')\n",
    "        plt.ylabel('f(x)')\n",
    "        plt.title('Piecewise Function: Exponential Growth, Peak, Drop, Linear Growth, and Repeat')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.axhline(y=self.func_y_max, color='gray', linestyle='--')\n",
    "        plt.axhline(y=self.func_y_min, color='gray', linestyle='--')\n",
    "        plt.axvline(x=self.func_x_drop, color='gray', linestyle='--')\n",
    "        plt.axvline(x=self.func_x_max, color='gray', linestyle='--')\n",
    "        plt.axhline(y = 0, color = 'r', linestyle = '-') \n",
    "        plt.axhline(y = self.act_threshold, color = 'r', linestyle = '-') \n",
    "        plt.show()\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "\n",
    "som_shape = (4, 4)\n",
    "func_x_max = 50\n",
    "func_x_drop = 30 \n",
    "func_y_max = 10 \n",
    "func_y_min = -7 \n",
    "act_threshold = 5\n",
    "\n",
    "inst_w = InstinctiveWeights(som_shape)\n",
    "inst_l= InstinctiveLayer(\n",
    "    som_shape = som_shape,\n",
    "    func_x_max = func_x_max, \n",
    "    func_x_drop = func_x_drop, \n",
    "    func_y_max = func_y_max, \n",
    "    func_y_min = func_y_min, \n",
    "    act_threshold = act_threshold,\n",
    ")\n",
    "\n",
    "inst_l.plot_act_func()\n",
    "\n",
    "\n",
    "def get_act():\n",
    "    inst_l.step(inst_w.get_weight_matrix(), np.random.uniform(low=0, high=1, size=som_shape))\n",
    "    return inst_l.get_activations().numpy(), inst_l.charges.numpy()\n",
    "\n",
    "\n",
    "_ = [inst_w.reinforce_connection(**connection) \n",
    "    for connection in [\n",
    "        {'n1': (0, 3), 'n2': (0, 3)},\n",
    "        {'n1': (0, 3), 'n2': (0, 3)},\n",
    "        {'n1': (0, 3), 'n2': (0, 3)},\n",
    "        {'n1': (0, 3), 'n2': (0, 3)},\n",
    "        {'n1': (0, 3), 'n2': (0, 3)},\n",
    "        {'n1': (0, 3), 'n2': (0, 3)},\n",
    "        {'n1': (0, 3), 'n2': (0, 3)},\n",
    "        {'n1': (0, 3), 'n2': (0, 0)},\n",
    "        {'n1': (0, 0), 'n2': (0, 0)},\n",
    "        {'n1': (0, 0), 'n2': (0, 0)},\n",
    "        {'n1': (0, 0), 'n2': (0, 1)},\n",
    "        {'n1': (0, 1), 'n2': (1, 0)},\n",
    "    ]]\n",
    "acts = [get_act() for _ in range(100)]\n",
    "\n",
    "_ = [inst_w.reinforce_connection(**connection) \n",
    "    for connection in [\n",
    "        {'n1': (0, 1), 'n2': (1, 0)},\n",
    "        {'n1': (0, 1), 'n2': (1, 0)},\n",
    "        {'n1': (1, 0), 'n2': (2, 2)},\n",
    "        {'n1': (2, 2), 'n2': (2, 2)},\n",
    "        {'n1': (2, 2), 'n2': (0, 3)},\n",
    "        {'n1': (2, 2), 'n2': (0, 3)},\n",
    "        {'n1': (2, 2), 'n2': (0, 3)},\n",
    "    ]]\n",
    "acts.extend([get_act() for _ in range(100)])\n",
    "\n",
    "arrays = [act[0] for act in acts]\n",
    "\n",
    "# Determine the number of subplots\n",
    "num_arrays = len(arrays)\n",
    "n = arrays[0].shape[0]\n",
    "\n",
    "# Determine the grid size\n",
    "cols = int(np.ceil(np.sqrt(num_arrays)))\n",
    "rows = int(np.ceil(num_arrays / cols))\n",
    "\n",
    "# Create the subplots\n",
    "fig, axes = plt.subplots(rows, cols, figsize=(8, 5))\n",
    "\n",
    "# Plot each array in its subplot\n",
    "for i, array in enumerate(arrays):\n",
    "    ax = axes.flat[i]\n",
    "    cax = ax.matshow(array, cmap='viridis', vmin=0, vmax=1)\n",
    "    fig.colorbar(cax, ax=ax)\n",
    "    ax.set_title(f'Array {i + 1}')\n",
    "\n",
    "# Remove any empty subplots\n",
    "for j in range(i + 1, len(axes.flat)):\n",
    "    fig.delaxes(axes.flat[j])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### **Instinctive Network**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InstinctiveNetwork:\n",
    "\n",
    "    def __init__(self, som_dims, input_dim, som_kwargs, inst_net_kwargs):\n",
    "        self.som_dims = som_dims\n",
    "        self.input_dim = input_dim\n",
    "        self.som = SOM(*self.som_dims, self.input_dim, **som_kwargs)\n",
    "        self.inner_weights = InstinctiveWeights(self.som_dims)\n",
    "        self.inner_layer = InstinctiveLayer(som_shape = self.som_dims, **inst_net_kwargs)\n",
    "        self.last_winner = tf.Variable([-1, -1], dtype=tf.int32)\n",
    "\n",
    "\n",
    "    @tf.function\n",
    "    def train_som(self, data):\n",
    "        self.som.train(data)\n",
    "        return\n",
    "\n",
    "\n",
    "    @tf.function\n",
    "    def reinforce_connection(self, data):\n",
    "        som_winner = self.som.get_bmu(data)\n",
    "        som_winner = self.som.index_to_2d(som_winner)\n",
    "\n",
    "        valid_last_winner = tf.not_equal(self.last_winner[0], -1)\n",
    "        \n",
    "        def reinforce():\n",
    "            self.inner_weights.reinforce_connection(\n",
    "                (self.last_winner[0], self.last_winner[1]),\n",
    "                som_winner\n",
    "            )\n",
    "        \n",
    "        tf.cond(valid_last_winner, reinforce, lambda: None)\n",
    "        self.last_winner.assign(som_winner)\n",
    "        return\n",
    "    \n",
    "\n",
    "    @tf.function\n",
    "    def reset_charges(self):\n",
    "        self.inner_layer.reset_charges()\n",
    "        self.last_winner.assign([-1, -1])\n",
    "        return\n",
    "\n",
    "\n",
    "    @tf.function\n",
    "    def get_output(self, data, reinforce=True):\n",
    "        if reinforce:\n",
    "            self.inner_weights.step()\n",
    "            self.reinforce_connection(data)\n",
    "\n",
    "        som_act = self.som.activate(tf.expand_dims(data, 0))\n",
    "        som_act = 1 - ((som_act - tf.reduce_min(som_act)) / (tf.reduce_max(som_act) - tf.reduce_min(som_act)))\n",
    "        \n",
    "        som_act_dist = tf.where(som_act < 0.95, tf.zeros_like(som_act), som_act)\n",
    "\n",
    "        weights = self.inner_weights.get_weight_matrix()\n",
    "        self.inner_layer.step(weights, som_act_dist)\n",
    "\n",
    "        active = self.inner_layer.get_act_array()\n",
    "        return active, som_act"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "\n",
    "inst_net = InstinctiveNetwork(\n",
    "    som_dims = (5, 5), \n",
    "    input_dim = 16,\n",
    "    som_kwargs = {\n",
    "        'n_iterations': 500,\n",
    "        'alpha': 0.5,\n",
    "        'sigma': 3,\n",
    "    }, \n",
    "    inst_net_kwargs = {\n",
    "        'func_x_max': 50,\n",
    "        'func_x_drop': 30,\n",
    "        'func_y_max': 10,\n",
    "        'func_y_min': -7,\n",
    "        'act_threshold': 5,\n",
    "    }\n",
    ")\n",
    "\n",
    "data = np.random.rand(100, 16)\n",
    "inst_net.train_som(data)\n",
    "out = []\n",
    "\n",
    "for i in data:\n",
    "    inst_net.reinforce_connection(i)\n",
    "    out.append(inst_net.get_output(i))\n",
    "\n",
    "display(np.shape(out))\n",
    "\n",
    "# Create the subplots\n",
    "fig, axes = plt.subplots(10, 10, figsize=(8, 5))\n",
    "\n",
    "# Plot each array in its subplot\n",
    "for i, array in enumerate(out):\n",
    "    ax = axes.flat[i]\n",
    "    cax = ax.matshow(array[-1].numpy(), cmap='viridis', vmin=0, vmax=1)\n",
    "    fig.colorbar(cax, ax=ax)\n",
    "    ax.set_title(f'Array {i + 1}')\n",
    "\n",
    "# Remove any empty subplots\n",
    "for j in range(i + 1, len(axes.flat)):\n",
    "    fig.delaxes(axes.flat[j])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### **Actor**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Actor(Model):\n",
    "    def __init__(self, s_inp_dim, s_fc1_dim, con_inp_dim, con_fc1_dim, fc2_dim, fc3_dim, fc4_dim, fc5_dim, out_dim, act_range, lr, tau):\n",
    "        super(Actor, self).__init__()\n",
    "        self.act_range = act_range\n",
    "        self.tau = tau\n",
    "        \n",
    "        self.s_fc1 = Dense(s_fc1_dim, activation='relu')\n",
    "        self.s_bn1 = BatchNormalization()\n",
    "        \n",
    "        self.con_fc1 = Dense(con_fc1_dim, activation='relu')\n",
    "        self.con_bn1 = BatchNormalization()\n",
    "        \n",
    "        self.fc2 = Dense(fc2_dim, activation='relu')\n",
    "        self.bn2 = BatchNormalization()\n",
    "        \n",
    "        self.fc3 = Dense(fc3_dim, activation='relu')\n",
    "        self.bn3 = BatchNormalization()\n",
    "\n",
    "        self.fc4 = Dense(fc4_dim, activation='relu')\n",
    "        self.bn4 = BatchNormalization()\n",
    "\n",
    "        self.fc5 = Dense(fc5_dim, activation='relu')\n",
    "        self.bn5 = BatchNormalization()\n",
    "        \n",
    "        self.out = Dense(out_dim, activation='tanh')\n",
    "        \n",
    "        self.optimizer = Adam(learning_rate=lr)\n",
    "\n",
    "\n",
    "    @tf.function\n",
    "    def call(self, state, context):\n",
    "        s = self.s_fc1(state)\n",
    "        s = self.s_bn1(s)\n",
    "        \n",
    "        c = self.con_fc1(context)\n",
    "        c = self.con_bn1(c)\n",
    "        \n",
    "        x = tf.concat([s, c], axis=1)\n",
    "        \n",
    "        x = self.fc2(x)\n",
    "        x = self.bn2(x)\n",
    "        \n",
    "        x = self.fc3(x)\n",
    "        x = self.bn3(x)\n",
    "\n",
    "        x = self.fc4(x)\n",
    "        x = self.bn4(x)\n",
    "\n",
    "        x = self.fc5(x)\n",
    "        x = self.bn5(x)\n",
    "        \n",
    "        x = self.out(x)\n",
    "        return x * self.act_range\n",
    "\n",
    "\n",
    "    @tf.function\n",
    "    def transfer_weights(self, target_model):\n",
    "        for a, b in zip(target_model.variables, self.variables):\n",
    "            a.assign(self.tau * b + (1 - self.tau) * a)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### **Critic**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Critic(Model):\n",
    "    def __init__(self, state_inp_dim, state_fc1_dim, action_inp_dim, action_fc1_dim, conc_fc1_dim, conc_fc2_dim, conc_fc3_dim, conc_fc4_dim, out_dim, lr, tau):\n",
    "        super(Critic, self).__init__()\n",
    "        self.tau = tau\n",
    "        \n",
    "        self.s_fc1 = Dense(state_fc1_dim, activation='relu')\n",
    "        self.s_bn1 = BatchNormalization()\n",
    "        \n",
    "        self.a_fc1 = Dense(action_fc1_dim, activation='relu')\n",
    "        self.a_bn1 = BatchNormalization()\n",
    "        \n",
    "        self.fc1 = Dense(conc_fc1_dim, activation='relu')\n",
    "        self.bn1 = BatchNormalization()\n",
    "        \n",
    "        self.fc2 = Dense(conc_fc2_dim, activation='relu')\n",
    "        self.bn2 = BatchNormalization()\n",
    "\n",
    "        self.fc3 = Dense(conc_fc3_dim, activation='relu')\n",
    "        self.bn3 = BatchNormalization()\n",
    "\n",
    "        self.fc4 = Dense(conc_fc4_dim, activation='relu')\n",
    "        self.bn4 = BatchNormalization()\n",
    "        \n",
    "        self.out = Dense(out_dim, activation='linear')\n",
    "        \n",
    "        self.optimizer = Adam(learning_rate=lr)\n",
    "\n",
    "    @tf.function\n",
    "    def call(self, state, action):\n",
    "        s = self.s_fc1(state)\n",
    "        s = self.s_bn1(s)\n",
    "        \n",
    "        a = self.a_fc1(action)\n",
    "        a = self.a_bn1(a)\n",
    "        \n",
    "        x = tf.concat([s, a], axis=1)\n",
    "        \n",
    "        x = self.fc1(x)\n",
    "        x = self.bn1(x)\n",
    "        \n",
    "        x = self.fc2(x)\n",
    "        x = self.bn2(x)\n",
    "\n",
    "        x = self.fc3(x)\n",
    "        x = self.bn3(x)\n",
    "\n",
    "        x = self.fc4(x)\n",
    "        x = self.bn4(x)\n",
    "        \n",
    "        x = self.out(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "    @tf.function\n",
    "    def transfer_weights(self, target_model):\n",
    "        for a, b in zip(target_model.variables, self.variables):\n",
    "            a.assign(self.tau * b + (1 - self.tau) * a)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### **DDPG Agent**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DDPGAgent(object):\n",
    "    def __init__(\n",
    "        self, state_dim, action_dim, action_min, action_max, \n",
    "        memory_size, batch_size, gamma, a_lr, c_lr, tau, epsilon, \n",
    "        epsilon_decay, epsilon_min, max_steps, env_name\n",
    "    ):\n",
    "        \n",
    "        self.state_dim = state_dim\n",
    "        self.action_dim = action_dim\n",
    "        self.action_min = action_min\n",
    "        self.action_max = action_max\n",
    "        self.memory_size = memory_size\n",
    "        self.batch_size = batch_size\n",
    "        self.gamma = gamma\n",
    "        self.a_lr = a_lr\n",
    "        self.c_lr = c_lr\n",
    "        self.tau = tau\n",
    "        self.epsilon = epsilon\n",
    "        self.epsilon_decay = epsilon_decay\n",
    "        self.epsilon_min = epsilon_min\n",
    "        self.max_steps = max_steps\n",
    "        self.env_name = env_name\n",
    "\n",
    "        self.noise = OUActionNoise(mean=np.zeros(action_dim), sigma=0.5, theta=0.2)\n",
    "\n",
    "        #Creates the Replay Buffer\n",
    "        self.memory = ReplayBuffer(self.memory_size, self.batch_size)\n",
    "\n",
    "        # creates instinctive network\n",
    "        som_dim = (15, 15)\n",
    "        self.inst_net = InstinctiveNetwork(\n",
    "            som_dims = som_dim, \n",
    "            input_dim = self.state_dim,\n",
    "            som_kwargs = {\n",
    "                'n_iterations': 1,\n",
    "                'alpha': 1e-3,\n",
    "                'sigma': 0.7,\n",
    "            }, \n",
    "            inst_net_kwargs = {\n",
    "                'func_x_max': 50,\n",
    "                'func_x_drop': 40,\n",
    "                'func_y_max': 10,\n",
    "                'func_y_min': -7,\n",
    "                'act_threshold': 4,\n",
    "            }\n",
    "        )\n",
    "\n",
    "        self.actor, self.actor_target = [Actor(\n",
    "            s_inp_dim=self.state_dim, \n",
    "            s_fc1_dim=512,\n",
    "            con_inp_dim=np.prod(som_dim), \n",
    "            con_fc1_dim=512,\n",
    "            fc2_dim=2048, \n",
    "            fc3_dim=512,\n",
    "            fc4_dim=256,\n",
    "            fc5_dim=32,\n",
    "            out_dim=self.action_dim, \n",
    "            act_range=self.action_max, \n",
    "            lr=self.a_lr, \n",
    "            tau=self.tau,\n",
    "        ) for _ in range(2)]\n",
    "        self.actor_target.set_weights(self.actor.get_weights())\n",
    "\n",
    "        self.critic, self.critic_target = [Critic(\n",
    "            state_inp_dim=self.state_dim, \n",
    "            state_fc1_dim=256, \n",
    "            action_inp_dim=self.action_dim, \n",
    "            action_fc1_dim=128,\n",
    "            conc_fc1_dim=512, \n",
    "            conc_fc2_dim=256,\n",
    "            conc_fc3_dim=128,\n",
    "            conc_fc4_dim=64,\n",
    "            out_dim=1,\n",
    "            lr=self.c_lr, \n",
    "            tau=self.tau,\n",
    "        ) for _ in range(2)]\n",
    "        self.critic_target.set_weights(self.critic.get_weights())\n",
    "        \n",
    "        self.create_plot()\n",
    "        return\n",
    "\n",
    "\n",
    "    def create_plot(self):\n",
    "        # Create a figure for SOM activation visualization\n",
    "        self.fig = plt.figure()\n",
    "\n",
    "        self.returns = self.fig.add_subplot(221)\n",
    "        self.returns.title.set_text('Retruns')\n",
    "\n",
    "        self.n_steps = self.fig.add_subplot(223)\n",
    "        self.n_steps.title.set_text('N Steps')\n",
    "\n",
    "        self.som_val = self.fig.add_subplot(222)\n",
    "        self.som_val.title.set_text('SOM val')\n",
    "\n",
    "        self.som_act = self.fig.add_subplot(224)\n",
    "        self.som_act.title.set_text('SOM Activation')\n",
    "\n",
    "        self.fig.show()\n",
    "        return\n",
    "\n",
    "\n",
    "    def update_plots(self, returns=None, n_steps=None, som_val=None, som_act=None):\n",
    "        # Update the SOM activation plot\n",
    "        if returns is not None:\n",
    "            self.returns.plot(np.arange(len(returns)), returns)\n",
    "\n",
    "        if n_steps is not None:\n",
    "            self.n_steps.plot(np.arange(len(returns)), n_steps)\n",
    "\n",
    "        if som_val is not None:\n",
    "            self.som_val.imshow(som_val)\n",
    "\n",
    "        if som_act is not None:\n",
    "            self.som_act.imshow(np.reshape(som_act, np.shape(som_val)))\n",
    "\n",
    "        self.fig.canvas.draw()\n",
    "        self.fig.canvas.flush_events()\n",
    "        return\n",
    "\n",
    "\n",
    "    @tf.function\n",
    "    def policy(self, state, explore=True):\n",
    "        context, som_act = self.inst_net.get_output(state)\n",
    "        action = self.actor(tf.expand_dims(state, 0), tf.expand_dims(context, 0))[0]\n",
    "\n",
    "        if explore:\n",
    "            if tf.random.uniform(()) < self.epsilon:\n",
    "                noise = self.noise()\n",
    "                action += noise\n",
    "\n",
    "        return tf.clip_by_value(action, self.action_min, self.action_max), context, som_act\n",
    "\n",
    "\n",
    "    @tf.function\n",
    "    def learn(self, states, actions, rewards, next_states, contexts, next_contexts, done):\n",
    "        # Train SOM using TensorFlow operations\n",
    "        all_states = tf.concat([states, next_states], axis=0)\n",
    "        self.inst_net.train_som(all_states)\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            target_actions = self.actor_target(next_states, next_contexts)\n",
    "            target_q_values = self.critic_target(next_states, target_actions)\n",
    "            y = rewards + self.gamma * target_q_values * (1 - done)\n",
    "            \n",
    "            q_values = self.critic(states, actions)\n",
    "            critic_loss = tf.reduce_mean(tf.square(y - q_values))\n",
    "\n",
    "        critic_grad = tape.gradient(critic_loss, self.critic.trainable_variables)\n",
    "        self.critic.optimizer.apply_gradients(zip(critic_grad, self.critic.trainable_variables))\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            actions = self.actor(states, contexts)\n",
    "            critic_value = self.critic(states, actions)\n",
    "            actor_loss = -tf.reduce_mean(critic_value)\n",
    "\n",
    "        actor_grad = tape.gradient(actor_loss, self.actor.trainable_variables)\n",
    "        self.actor.optimizer.apply_gradients(zip(actor_grad, self.actor.trainable_variables))\n",
    "\n",
    "        self.actor.transfer_weights(self.actor_target)\n",
    "        self.critic.transfer_weights(self.critic_target)\n",
    "\n",
    "        return actor_loss, critic_loss\n",
    "\n",
    "\n",
    "    def act(self):\n",
    "        #Reset the envirorment\n",
    "        env2 = gym.make(self.env_name, hardcore=True, render_mode='human')\n",
    "        state, _ = env2.reset()\n",
    "        self.inst_net.reset_charges()\n",
    "        done = False\n",
    "        step = 0\n",
    "        \n",
    "        while not done:\n",
    "            env2.render()\n",
    "            action, context, _ = self.policy(state, explore=False)\n",
    "            state, _, done, _, _ = env2.step(action.numpy())\n",
    "            step += 1\n",
    "            done = done or (step > self.max_steps)\n",
    "        \n",
    "        env2.close()\n",
    "        return\n",
    "\n",
    "\n",
    "    def train(self, env, num_episodes, verbose, verbose_num, end_on_complete, complete_num, complete_value, act_after_batch, plot_act):\n",
    "        scores_history = []\n",
    "        steps_history = []\n",
    "\n",
    "        print(\"BEGIN\\n\")\n",
    "        complete = 0\n",
    "\n",
    "        for episode in range(num_episodes):\n",
    "            state, _ = env.reset()\n",
    "            self.inst_net.reset_charges()\n",
    "            done = False\n",
    "            score = 0\n",
    "            steps = 0\n",
    "\n",
    "            while not done:\n",
    "                action, context, som_val = self.policy(state)\n",
    "                if plot_act: self.update_plots(som_val=som_val.numpy(), som_act=context.numpy())\n",
    "\n",
    "                if verbose:\n",
    "                    print(\"\\r                                                          \", end=\"\")\n",
    "                    print(f\"\\rEpisode: {str(episode+1)} \\tStep: {str(steps)} \\tReward: {str(score)}\", end=\"\")\n",
    "                \n",
    "                next_state, reward, done, _, _ = env.step(action.numpy())\n",
    "                _, next_context, _ = self.policy(next_state)\n",
    "                \n",
    "                self.memory.append(state, action.numpy(), reward, next_state, context, next_context, done)\n",
    "                \n",
    "                if self.memory.isMin():\n",
    "                    experiences = self.memory.sample()\n",
    "                    states, actions, rewards, next_states, contexts, next_contexts, dones = [np.array([exp[i] for exp in experiences]) for i in range(7)]\n",
    "                    \n",
    "                    self.learn(\n",
    "                        tf.convert_to_tensor(states, dtype=tf.float32),\n",
    "                        tf.convert_to_tensor(actions, dtype=tf.float32),\n",
    "                        tf.convert_to_tensor(rewards, dtype=tf.float32),\n",
    "                        tf.convert_to_tensor(next_states, dtype=tf.float32),\n",
    "                        tf.convert_to_tensor(contexts, dtype=tf.float32),\n",
    "                        tf.convert_to_tensor(next_contexts, dtype=tf.float32),\n",
    "                        tf.convert_to_tensor(dones, dtype=tf.float32)\n",
    "                    )\n",
    "                    self.epsilon = max(self.epsilon_min, self.epsilon * self.epsilon_decay)\n",
    "\n",
    "                state = next_state\n",
    "                score += reward\n",
    "                steps += 1\n",
    "                done = done or (steps > self.max_steps)\n",
    "\n",
    "\n",
    "            scores_history.append(score)\n",
    "            steps_history.append(steps)\n",
    "            self.update_plots(returns=scores_history, n_steps=steps_history)\n",
    "            \n",
    "            if(score >= complete_value):\n",
    "                complete += 1\n",
    "                if end_on_complete and complete >= complete_num: break\n",
    "            \n",
    "            if((episode+1)%verbose_num == 0):\n",
    "                print(\"\\r                                                                                                          \", end=\"\")\n",
    "                print(f'''\\rEpisodes: {episode+1}/{num_episodes}\\n\\tTotal reward: {np.mean(scores_history[-verbose_num:])} +- {np.std(scores_history[-verbose_num:])}\\n\\tNum. steps: {np.mean(steps_history[-verbose_num:])} +- {np.std(steps_history[-verbose_num:])}\\n\\tCompleted: {complete}\\n--------------------------''')\n",
    "                if act_after_batch: self.act()\n",
    "                complete = 0\n",
    "\n",
    "        print(\"\\nFINISHED\")\n",
    "        \n",
    "        return scores_history, steps_history\n",
    "\n",
    "\n",
    "    def save(self, path):\n",
    "        self.actor.saveModel(path)\n",
    "        self.critic.saveModel(path)\n",
    "        return\n",
    "\n",
    "\n",
    "    def load(self, a_path, c_path):\n",
    "        self.actor.loadModel(a_path)\n",
    "        self.critic.loadModel(c_path)\n",
    "        return\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### **Test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-10 16:15:45.028633: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    }
   ],
   "source": [
    "name = \"BipedalWalker-v3\"\n",
    "env = gym.make(name, hardcore=True)\n",
    "\n",
    "state_dim = env.observation_space.shape[0]\n",
    "action_dim = env.action_space.shape[0]\n",
    "action_min = env.action_space.low\n",
    "action_max = env.action_space.high\n",
    "\n",
    "agent = DDPGAgent(\n",
    "    state_dim = state_dim, \n",
    "    action_dim = action_dim, \n",
    "    action_min = action_min, \n",
    "    action_max = action_max,\n",
    "    env_name = name,\n",
    "    memory_size = 1000000,\n",
    "    batch_size = 256,\n",
    "    gamma = 0.99,\n",
    "    a_lr = 3e-5,\n",
    "    c_lr = 5e-4,\n",
    "    tau = 1e-4,\n",
    "    epsilon = 1,\n",
    "    epsilon_decay = 0.9999,\n",
    "    epsilon_min = 0.4,\n",
    "    max_steps = 1600,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEGIN\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 1 \tStep: 63 \tReward: -13.794356586412839         "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43menv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_episodes\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3000\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose_num\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mend_on_complete\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcomplete_num\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcomplete_value\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m300\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mact_after_batch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mplot_act\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[1;32m     11\u001b[0m \u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[12], line 201\u001b[0m, in \u001b[0;36mDDPGAgent.train\u001b[0;34m(self, env, num_episodes, verbose, verbose_num, end_on_complete, complete_num, complete_value, act_after_batch, plot_act)\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m done:\n\u001b[1;32m    200\u001b[0m     action, context, som_val \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpolicy(state)\n\u001b[0;32m--> 201\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m plot_act: \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate_plots\u001b[49m\u001b[43m(\u001b[49m\u001b[43msom_val\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msom_val\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msom_act\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    203\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m verbose:\n\u001b[1;32m    204\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\r\u001b[39;00m\u001b[38;5;124m                                                          \u001b[39m\u001b[38;5;124m\"\u001b[39m, end\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[12], line 117\u001b[0m, in \u001b[0;36mDDPGAgent.update_plots\u001b[0;34m(self, returns, n_steps, som_val, som_act)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m som_act \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msom_act\u001b[38;5;241m.\u001b[39mimshow(np\u001b[38;5;241m.\u001b[39mreshape(som_act, np\u001b[38;5;241m.\u001b[39mshape(som_val)))\n\u001b[0;32m--> 117\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcanvas\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfig\u001b[38;5;241m.\u001b[39mcanvas\u001b[38;5;241m.\u001b[39mflush_events()\n\u001b[1;32m    119\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[0;32m~/.application-data/miniconda3/envs/rl-tf/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:387\u001b[0m, in \u001b[0;36mFigureCanvasAgg.draw\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    384\u001b[0m \u001b[38;5;66;03m# Acquire a lock on the shared font cache.\u001b[39;00m\n\u001b[1;32m    385\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtoolbar\u001b[38;5;241m.\u001b[39m_wait_cursor_for_draw_cm() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtoolbar\n\u001b[1;32m    386\u001b[0m       \u001b[38;5;28;01melse\u001b[39;00m nullcontext()):\n\u001b[0;32m--> 387\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfigure\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    388\u001b[0m     \u001b[38;5;66;03m# A GUI class may be need to update a window using this draw, so\u001b[39;00m\n\u001b[1;32m    389\u001b[0m     \u001b[38;5;66;03m# don't forget to call the superclass.\u001b[39;00m\n\u001b[1;32m    390\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mdraw()\n",
      "File \u001b[0;32m~/.application-data/miniconda3/envs/rl-tf/lib/python3.9/site-packages/matplotlib/artist.py:95\u001b[0m, in \u001b[0;36m_finalize_rasterization.<locals>.draw_wrapper\u001b[0;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(draw)\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdraw_wrapper\u001b[39m(artist, renderer, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m---> 95\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[43martist\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m renderer\u001b[38;5;241m.\u001b[39m_rasterizing:\n\u001b[1;32m     97\u001b[0m         renderer\u001b[38;5;241m.\u001b[39mstop_rasterizing()\n",
      "File \u001b[0;32m~/.application-data/miniconda3/envs/rl-tf/lib/python3.9/site-packages/matplotlib/artist.py:72\u001b[0m, in \u001b[0;36mallow_rasterization.<locals>.draw_wrapper\u001b[0;34m(artist, renderer)\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m artist\u001b[38;5;241m.\u001b[39mget_agg_filter() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     70\u001b[0m         renderer\u001b[38;5;241m.\u001b[39mstart_filter()\n\u001b[0;32m---> 72\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[43martist\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     74\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m artist\u001b[38;5;241m.\u001b[39mget_agg_filter() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/.application-data/miniconda3/envs/rl-tf/lib/python3.9/site-packages/matplotlib/figure.py:3162\u001b[0m, in \u001b[0;36mFigure.draw\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m   3159\u001b[0m             \u001b[38;5;66;03m# ValueError can occur when resizing a window.\u001b[39;00m\n\u001b[1;32m   3161\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpatch\u001b[38;5;241m.\u001b[39mdraw(renderer)\n\u001b[0;32m-> 3162\u001b[0m     \u001b[43mmimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_draw_list_compositing_images\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3163\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43martists\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msuppressComposite\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3165\u001b[0m     renderer\u001b[38;5;241m.\u001b[39mclose_group(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfigure\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m   3166\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "File \u001b[0;32m~/.application-data/miniconda3/envs/rl-tf/lib/python3.9/site-packages/matplotlib/image.py:132\u001b[0m, in \u001b[0;36m_draw_list_compositing_images\u001b[0;34m(renderer, parent, artists, suppress_composite)\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m not_composite \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m has_images:\n\u001b[1;32m    131\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m artists:\n\u001b[0;32m--> 132\u001b[0m         \u001b[43ma\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    134\u001b[0m     \u001b[38;5;66;03m# Composite any adjacent images together\u001b[39;00m\n\u001b[1;32m    135\u001b[0m     image_group \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m~/.application-data/miniconda3/envs/rl-tf/lib/python3.9/site-packages/matplotlib/artist.py:72\u001b[0m, in \u001b[0;36mallow_rasterization.<locals>.draw_wrapper\u001b[0;34m(artist, renderer)\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m artist\u001b[38;5;241m.\u001b[39mget_agg_filter() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     70\u001b[0m         renderer\u001b[38;5;241m.\u001b[39mstart_filter()\n\u001b[0;32m---> 72\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[43martist\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     74\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m artist\u001b[38;5;241m.\u001b[39mget_agg_filter() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/.application-data/miniconda3/envs/rl-tf/lib/python3.9/site-packages/matplotlib/axes/_base.py:3143\u001b[0m, in \u001b[0;36m_AxesBase.draw\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m   3140\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m artists_rasterized:\n\u001b[1;32m   3141\u001b[0m     _draw_rasterized(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfigure, artists_rasterized, renderer)\n\u001b[0;32m-> 3143\u001b[0m \u001b[43mmimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_draw_list_compositing_images\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3144\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43martists\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfigure\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msuppressComposite\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3146\u001b[0m renderer\u001b[38;5;241m.\u001b[39mclose_group(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maxes\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m   3147\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstale \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/.application-data/miniconda3/envs/rl-tf/lib/python3.9/site-packages/matplotlib/image.py:132\u001b[0m, in \u001b[0;36m_draw_list_compositing_images\u001b[0;34m(renderer, parent, artists, suppress_composite)\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m not_composite \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m has_images:\n\u001b[1;32m    131\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m artists:\n\u001b[0;32m--> 132\u001b[0m         \u001b[43ma\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    134\u001b[0m     \u001b[38;5;66;03m# Composite any adjacent images together\u001b[39;00m\n\u001b[1;32m    135\u001b[0m     image_group \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m~/.application-data/miniconda3/envs/rl-tf/lib/python3.9/site-packages/matplotlib/artist.py:72\u001b[0m, in \u001b[0;36mallow_rasterization.<locals>.draw_wrapper\u001b[0;34m(artist, renderer)\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m artist\u001b[38;5;241m.\u001b[39mget_agg_filter() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     70\u001b[0m         renderer\u001b[38;5;241m.\u001b[39mstart_filter()\n\u001b[0;32m---> 72\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[43martist\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     74\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m artist\u001b[38;5;241m.\u001b[39mget_agg_filter() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/.application-data/miniconda3/envs/rl-tf/lib/python3.9/site-packages/matplotlib/axis.py:1422\u001b[0m, in \u001b[0;36mAxis.draw\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m   1419\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m   1420\u001b[0m renderer\u001b[38;5;241m.\u001b[39mopen_group(\u001b[38;5;18m__name__\u001b[39m, gid\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_gid())\n\u001b[0;32m-> 1422\u001b[0m ticks_to_draw \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_ticks\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1423\u001b[0m tlb1, tlb2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_ticklabel_bboxes(ticks_to_draw, renderer)\n\u001b[1;32m   1425\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m tick \u001b[38;5;129;01min\u001b[39;00m ticks_to_draw:\n",
      "File \u001b[0;32m~/.application-data/miniconda3/envs/rl-tf/lib/python3.9/site-packages/matplotlib/axis.py:1306\u001b[0m, in \u001b[0;36mAxis._update_ticks\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1304\u001b[0m     tick\u001b[38;5;241m.\u001b[39mlabel1\u001b[38;5;241m.\u001b[39mset_text(label)\n\u001b[1;32m   1305\u001b[0m     tick\u001b[38;5;241m.\u001b[39mlabel2\u001b[38;5;241m.\u001b[39mset_text(label)\n\u001b[0;32m-> 1306\u001b[0m minor_locs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_minorticklocs\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1307\u001b[0m minor_labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mminor\u001b[38;5;241m.\u001b[39mformatter\u001b[38;5;241m.\u001b[39mformat_ticks(minor_locs)\n\u001b[1;32m   1308\u001b[0m minor_ticks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_minor_ticks(\u001b[38;5;28mlen\u001b[39m(minor_locs))\n",
      "File \u001b[0;32m~/.application-data/miniconda3/envs/rl-tf/lib/python3.9/site-packages/matplotlib/axis.py:1537\u001b[0m, in \u001b[0;36mAxis.get_minorticklocs\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1535\u001b[0m minor_locs \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mminor\u001b[38;5;241m.\u001b[39mlocator())\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mremove_overlapping_locs:\n\u001b[0;32m-> 1537\u001b[0m     major_locs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmajor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlocator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1538\u001b[0m     transform \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_scale\u001b[38;5;241m.\u001b[39mget_transform()\n\u001b[1;32m   1539\u001b[0m     tr_minor_locs \u001b[38;5;241m=\u001b[39m transform\u001b[38;5;241m.\u001b[39mtransform(minor_locs)\n",
      "File \u001b[0;32m~/.application-data/miniconda3/envs/rl-tf/lib/python3.9/site-packages/matplotlib/ticker.py:2171\u001b[0m, in \u001b[0;36mMaxNLocator.__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2169\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m   2170\u001b[0m     vmin, vmax \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxis\u001b[38;5;241m.\u001b[39mget_view_interval()\n\u001b[0;32m-> 2171\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtick_values\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvmin\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvmax\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.application-data/miniconda3/envs/rl-tf/lib/python3.9/site-packages/matplotlib/ticker.py:2179\u001b[0m, in \u001b[0;36mMaxNLocator.tick_values\u001b[0;34m(self, vmin, vmax)\u001b[0m\n\u001b[1;32m   2176\u001b[0m     vmin \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39mvmax\n\u001b[1;32m   2177\u001b[0m vmin, vmax \u001b[38;5;241m=\u001b[39m mtransforms\u001b[38;5;241m.\u001b[39mnonsingular(\n\u001b[1;32m   2178\u001b[0m     vmin, vmax, expander\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-13\u001b[39m, tiny\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-14\u001b[39m)\n\u001b[0;32m-> 2179\u001b[0m locs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raw_ticks\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvmin\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvmax\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2181\u001b[0m prune \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prune\n\u001b[1;32m   2182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m prune \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlower\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "File \u001b[0;32m~/.application-data/miniconda3/envs/rl-tf/lib/python3.9/site-packages/matplotlib/ticker.py:2109\u001b[0m, in \u001b[0;36mMaxNLocator._raw_ticks\u001b[0;34m(self, vmin, vmax)\u001b[0m\n\u001b[1;32m   2107\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_nbins \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m   2108\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxis \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 2109\u001b[0m         nbins \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mclip(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_tick_space\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m   2110\u001b[0m                         \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_min_n_ticks \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m), \u001b[38;5;241m9\u001b[39m)\n\u001b[1;32m   2111\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2112\u001b[0m         nbins \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m9\u001b[39m\n",
      "File \u001b[0;32m~/.application-data/miniconda3/envs/rl-tf/lib/python3.9/site-packages/matplotlib/axis.py:2794\u001b[0m, in \u001b[0;36mYAxis.get_tick_space\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2793\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_tick_space\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m-> 2794\u001b[0m     ends \u001b[38;5;241m=\u001b[39m \u001b[43mmtransforms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mBbox\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransformed\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2795\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maxes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransAxes\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfigure\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdpi_scale_trans\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2796\u001b[0m     length \u001b[38;5;241m=\u001b[39m ends\u001b[38;5;241m.\u001b[39mheight \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m72\u001b[39m\n\u001b[1;32m   2797\u001b[0m     \u001b[38;5;66;03m# Having a spacing of at least 2 just looks good.\u001b[39;00m\n",
      "File \u001b[0;32m~/.application-data/miniconda3/envs/rl-tf/lib/python3.9/site-packages/matplotlib/transforms.py:468\u001b[0m, in \u001b[0;36mBboxBase.transformed\u001b[0;34m(self, transform)\u001b[0m\n\u001b[1;32m    464\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    465\u001b[0m \u001b[38;5;124;03mConstruct a `Bbox` by statically transforming this one by *transform*.\u001b[39;00m\n\u001b[1;32m    466\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    467\u001b[0m pts \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_points()\n\u001b[0;32m--> 468\u001b[0m ll, ul, lr \u001b[38;5;241m=\u001b[39m \u001b[43mtransform\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    469\u001b[0m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[43mpts\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mpts\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpts\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mpts\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpts\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    470\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Bbox([ll, [lr[\u001b[38;5;241m0\u001b[39m], ul[\u001b[38;5;241m1\u001b[39m]]])\n",
      "File \u001b[0;32m~/.application-data/miniconda3/envs/rl-tf/lib/python3.9/site-packages/matplotlib/transforms.py:1502\u001b[0m, in \u001b[0;36mTransform.transform\u001b[0;34m(self, values)\u001b[0m\n\u001b[1;32m   1500\u001b[0m values \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masanyarray(values)\n\u001b[1;32m   1501\u001b[0m ndim \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39mndim\n\u001b[0;32m-> 1502\u001b[0m values \u001b[38;5;241m=\u001b[39m \u001b[43mvalues\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m((\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_dims))\n\u001b[1;32m   1504\u001b[0m \u001b[38;5;66;03m# Transform the values\u001b[39;00m\n\u001b[1;32m   1505\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform_affine(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform_non_affine(values))\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "agent.train(\n",
    "    env = env,\n",
    "    num_episodes = 3000,\n",
    "    verbose = True,\n",
    "    verbose_num = 10,\n",
    "    end_on_complete = True,\n",
    "    complete_num = 10,\n",
    "    complete_value = 300,\n",
    "    act_after_batch = True,\n",
    "    plot_act = False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7.14895815e-32, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [0.00000000e+00, 1.74162345e-33, 0.00000000e+00, ...,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [0.00000000e+00, 0.00000000e+00, 8.53059556e-34, ...,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       ...,\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "        6.97811946e-36, 4.70963275e-37, 0.00000000e+00],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "        4.70963275e-37, 2.31974275e-36, 9.09458667e-37],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "        0.00000000e+00, 9.09458667e-37, 1.16931224e-35]], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.inst_net.inner_weights.get_weight_matrix().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.act()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "vscode": {
   "interpreter": {
    "hash": "d2152fd7f0bbc62aa1baff8c990435d1e2c7175d001561303988032604c11a48"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
